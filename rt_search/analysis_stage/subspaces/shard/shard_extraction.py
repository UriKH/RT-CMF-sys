from rt_search.utils.types import *
from rt_search.utils.geometry.plane import Plane
from rt_search.configs.analysis import *
from rt_search.configs import (
    system as sys_config
)

from ramanujantools.cmf import CMF
from rt_search.analysis_stage.subspaces.shard.shard import Shard
from rt_search.analysis_stage.subspaces.shard.config import *
from rt_search.utils.geometry.point_generator import PointGenerator
from rt_search.utils.logger import Logger

from itertools import product
from functools import lru_cache, partial
from scipy.optimize import linprog
import numpy as np
from numpy import linalg
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor


class ShardExtractor:
    """
    A functional class in charge of the Shards extraction for later use
    """
    def __init__(self, const_name: str, cmf: CMF, shifts: Position):
        self.const_name = const_name
        self.cmf: CMF = cmf
        self.shifts: Position = shifts
        self.pool = ProcessPoolExecutor() if PARALLEL_SHARD_ANALYSIS else None
        self.hps, self.symbols = self.__extract_shard_hyperplanes(cmf)
        Logger(
            f'\n* symbols for this CMF: {self.symbols}\n* Shifts: {self.shifts}', Logger.Levels.info
        ).log(msg_prefix='\n')

        # This will be instantiated later on the first call to get_encoded_shards()
        self._mono_shard = len(self.hps) == 0
        self._encoded_shards = [tuple()] if self._mono_shard else None
        self._feasible_points = [[0] * len(self.symbols)] if self._mono_shard else None
        self._shards = [Shard(tuple(), self)] if self._mono_shard else None
        self._populated = False

    def __eq__(self, other):
        if isinstance(other, ShardExtractor):
            return self.cmf == other.cmf and self.shifts == other.shifts
        raise NotImplementedError

    @staticmethod
    def __proportional(expr1: sp.Expr, expr2: sp.Expr, symbols: List[sp.Symbol]) -> bool:
        # Build full coefficient vectors including the constant term
        coeffs1 = [expr1.coeff(s) for s in symbols] + [expr1.as_independent(*symbols, as_Add=True)[0]]
        coeffs2 = [expr2.coeff(s) for s in symbols] + [expr2.as_independent(*symbols, as_Add=True)[0]]

        v1, v2 = sp.Matrix(coeffs1), sp.Matrix(coeffs2)

        # Handle zero vector corner cases
        if v1.is_zero or v2.is_zero:
            return v1.is_zero and v2.is_zero
        return sp.Matrix.hstack(v1, v2).rank() == 1

    @staticmethod
    def _clac_hyperplanes_worker(mat):
        def __solve_shards(mat: sp.Matrix) -> Tuple[Set[EqTup], Set[EqTup]]:
            """
            Find the expressions for which the matrix is undefined or its determinant is 0
            :param mat: The matrix to preform the calculations on
            :return: The list of expressions for undefined hyperplanes (lhs, rhs);
            The list of expressions for zero determinant hyperplanes (lhs, rhs)
            """

            def __transform(l: List[Dict]) -> Set[EqTup]:
                """
                Convert a list of dictionaries generated by sympy.solve() into a set of lhs, rhs tuples
                :param l: The list of dictionaries to transform
                :return: The transformed list
                """
                return set(tuple(set(sol.items()))[0] for sol in l)

            l = []
            for v in mat.iter_values():
                if (den := v.as_numer_denom()[1]) == 1:
                    continue
                l += [{sym: sol} for sym in den.free_symbols for sol in sp.solve(den, sym)]
            return __transform(l), __transform(sp.solve(mat.det()))

        undef, z_det = __solve_shards(mat)
        return undef.union(z_det)

    @staticmethod
    @lru_cache(maxsize=128 if SHARD_EXTRACTOR_CACHE else 0)
    def __expr_to_ineq(expr, symbols, greater_than_0: bool = True):
        """
        Prepare a linear expression of the form: ax + b > 0 \n
        to the form scipy.linprog() receives: -ax <= b - err \n
        (similarly for ax + b < 0: ax <= -b - err)
        :param expr: The expression to transform into the relevant inequality
        :param symbols: The symbols used in the expression
        :param greater_than_0: indicates the format
        :return: the row matching the expression and the constant in the scipy.linprog() format
        """
        coeffs = expr.as_coefficients_dict()
        a = [float(coeffs.get(v, 0)) for v in symbols]
        const = float(expr.as_independent(*symbols, as_Add=True)[0])

        if greater_than_0:
            # a·x + c >= 0  ⇔  -a·x <= c
            row = [-coef for coef in a]
            b = const - SHARD_EXTRACTOR_ERR
        else:
            # a·x + c <= 0  ⇔  a·x <= -c
            row = [coef for coef in a]
            b = -const - SHARD_EXTRACTOR_ERR
        return row, b

    @staticmethod
    def _validate_shard_worker(shard: ShardVec, hps: List[Plane], symbols: List[sp.Symbol]) -> Tuple[bool, List[int | float]]:
        """
        Checks if a shard vector is valid in the CMF
        :param shard: the shard vector +-1's vector that describes the shard
        :return: True if a corresponding shard exists, else False
        """
        A, b = [], []
        for ineq, indicator in zip(hps, shard):
            row, rhs = ShardExtractor.__expr_to_ineq(ineq.expression, tuple(symbols), indicator == 1)
            A.append(row)
            b.append(rhs)

        bounds = [(None, None)] * len(symbols)
        res = linprog(c=list(np.zeros(len(symbols))), bounds=bounds, A_ub=A, b_ub=b, method="highs")

        if res.success or res.status == 3:
            # status == 3 means "unbounded" in HiGHS, which is fine
            x = res.x.tolist() if res.x is not None else []
            return True, x
        return False, []

    def __extract_shard_hyperplanes(self, cmf: CMF) -> Tuple[List[Plane], List[sp.Symbol]]:
        """
        Extract the CMF's hyperplanes that form the shards
        :param cmf: The CMF to analyze
        :return: the list of sympy expressions describing the hyperplanes and a list of the symbols
        """

        def remove_duplicates(l: Set[EqTup]) -> List[EqTup]:
            """
            Converts the set of tuples (lhs, rhs) into a list of tuples such that we won't have doubles (filtering).
            :param l: The list to "unfreeze"
            :return: The filtered list of tuples (lhs, rhs)
            """
            clean = [set(tup) for tup in l]
            new_lst = set(tuple(tup) for tup in clean)
            return list(new_lst)  # type checker shouts, but this is correct!

        if PARALLEL_SHARD_ANALYSIS:
            results = self.pool.map(
                ShardExtractor._clac_hyperplanes_worker,
                cmf.matrices.values(),
                chunksize=HP_CALC_CHUNK
            )
            data = set().union(*results)
        else:
            data = set()
            for mat in cmf.matrices.values():
                data = data.union(ShardExtractor._clac_hyperplanes_worker(mat))

        data = remove_duplicates(data)
        symbols = list(cmf.matrices.keys())
        planes = [Plane(exp1 - exp2, symbols) for exp1, exp2 in data]
        filtered = [planes[-1]]

        # make sure planes are uniuqe
        i = len(planes) - 2
        while i >= 0:
            append = True
            for plane in filtered:
                if ShardExtractor.__proportional(planes[i].expression, plane.expression, plane.symbols):
                    append = False
                    break
            if append:
                filtered.append(planes[i])
            i -= 1
        return filtered, symbols

    def get_encoded_shards(self) -> List[ShardVec]:
        """
        Compute the Shards as Shard vector identifiers
        :return: A list of the vector identifiers
        """
        if self._encoded_shards is not None:
            return self._encoded_shards

        if self._mono_shard:
            self._encoded_shards = [tuple()]
            self._feasible_points = [[0] * len(self.symbols)]
            return self._encoded_shards

        perms = list(product([+1, -1], repeat=len(self.hps)))

        if PARALLEL_SHARD_ANALYSIS:
            vals = self.pool.map(
                partial(ShardExtractor._validate_shard_worker, hps=self.hps, symbols=self.symbols),
                perms,
                chunksize=SHARD_VALIDATION_CHUNK
            )
            shards_validated = [(perm, val[1]) for perm, val in zip(perms, vals) if val[0]]
        else:
            shards_validated = [
                (perm, val[1]) for perm in tqdm(perms, desc='Computing shards', **sys_config.TQDM_CONFIG)
                if (val := self._validate_shard_worker(perm, self.hps, self.symbols))[0]
            ]
        ShardExtractor.__expr_to_ineq.cache_clear()

        self._encoded_shards = [perm for perm, point in shards_validated]
        self._feasible_points = [point for _, point in shards_validated]
        return self._encoded_shards

    def get_shards(self) -> List[Shard]:
        if self._shards is None:
            self._shards = [Shard(shard_id, self) for shard_id in self.get_encoded_shards()]
        return self._shards

    def compute_feasible_points(self) -> Tuple[Dict[ShardVec, List[Position]], List[Position]]:
        shards = self.get_shards()
        point_classification = {shard_id: [] for shard_id in self._encoded_shards}
        shifted = [
            Position([int(c) for c in np.floor(np.array(p))], self.symbols) + self.shifts for p in self._feasible_points
        ]
        valid_shifted = []
        for shard, p in zip(shards, shifted):
            if shard.in_space(p)[0]:
                point_classification[shard.shard_id].append(p)
                valid_shifted.append(p)
        return point_classification, valid_shifted

    def populate_cmf_start_points(self,
                                  use_feasible: bool = True,
                                  expand_anyway: bool = False,
                                  clear_original: bool = True,
                                  start_method: str = 'cube') -> None:
        """
        The function populates the CMF's start points with the points that are within the shards.

        The function preforms the following steps:
        * First, use the estimate radius using the feasible points found in the process of finding the shards.
        * If the first stage was unsuccessful, enlarge the set of potential starting points by adding
         a cube of an increasing edge length.
        :param use_feasible: Try using the points already generated when finding the shards.
        :param expand_anyway: Even if start points are found using the feasible points, expand the set of
         starting points.
        :param clear_original: Clear the currently found start points.
        :param start_method: The method to use for generating starting points
            (cube / sphere of a specified radius computed internally)
        """
        if self._populated:
            return
        self._populated = True
        shards = self.get_shards()
        point_classification = {shard_id: [] for shard_id in self._encoded_shards}
        expansion_factor = np.sqrt(len(self.symbols))

        expand_search = use_feasible or expand_anyway
        valid_shifted = []

        # Start by computing the relevant feasible points if there are any
        if use_feasible:
            point_classification, valid_shifted = self.compute_feasible_points()
            for shard_id in point_classification:
                if len(point_classification[shard_id]) == 0:
                    expand_search = True
                    break
            if not expand_search and not expand_anyway:
                return

        first_iteration = True
        r = (max([linalg.norm(p.as_list()) for p in valid_shifted]) if valid_shifted else 0) + expansion_factor
        curr_points = PointGenerator.generate_via_shape(int(r), len(self.symbols), start_method, as_primitive=False)
        total_points = curr_points.copy()

        # Find possible start points within a cube
        expanded = 1
        while expand_search:
            expand_search = False

            if not first_iteration:
                if expanded > MAX_EXPANSIONS:
                    break
                curr_points, total_points = PointGenerator.expand_set(curr_points, signed_expansion=True)
                Logger(f'expanded search for start points {expanded}', Logger.Levels.info).log()
                expanded += 1
            first_iteration = False

            # classify points
            for point in curr_points:
                point = Position(list(point), self.symbols) + self.shifts
                encoded, valid = self.encode_point(point, self.hps)
                if not valid:
                    continue
                try:
                    point_classification[encoded].append(point)
                except KeyError:
                    Logger('Shard was not detected! Stopping... :(', Logger.Levels.fatal).log()

            # make sure all shards have a start point
            for shard_id in point_classification:
                if len(point_classification[shard_id]) == 0:
                    r += expansion_factor
                    expand_search = True
                    break
            curr_points = total_points

        for shard in shards:
            if clear_original:
                shard.clear_start_points()
            shard.add_start_points(point_classification[shard.shard_id], filtering=False)

    @staticmethod
    def encode_point(point: Position, hps: List[Plane]) -> Tuple[ShardVec, bool]:
        """
        Encodes the shard that the point is within its borders.
        :param point: The point as a tuple
        :param hps: The hyperplanes defining the shards
        :return: The Shard encoding +-1's vector, True if the point is not on a hyperplane, else False.
        """
        def sign(n):
            if abs(n) <= 1e-4:
                return 0
            return 1 if n > 0 else -1

        point.set_axis(hps[0].symbols)
        return (encoded := tuple(sign(float(plane.expression.subs(point).evalf())) for plane in hps)), 0 not in encoded
